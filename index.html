<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BioCLIP Project Hub | Foundation Models for the Tree of Life</title>
    <meta name="description" content="Central hub for the BioCLIP project. Find the right biological vision model for your research.">
    
    <link rel="stylesheet" href="css/variables.css">
    <link rel="stylesheet" href="css/style.css">
</head>
<body>

    <header class="site-header">
        <div class="container header-content">
            <a href="#" class="logo">
                <div class="logo-icon"></div>
                BioCLIP Project
            </a>
            <nav class="nav-links">
                <a href="#bioclip-2">BioCLIP 2</a>
                <a href="#bioclip-1">BioCLIP</a>
                <a href="#pybioclip">pybioclip</a>
                <a href="#collection">Data & Models</a>
            </nav>
        </div>
    </header>

    <section class="hero">
        <div class="container">
            <h1>Vision Foundation Models<br>for the Tree of Life</h1>
            <p>
                Bridging computer vision and biology. BioCLIP models learn hierarchical representations 
                of the natural world, enabling advanced species classification, trait prediction, and more.
            </p>
            <div class="hero-actions">
                <a href="#guide" class="btn btn-primary">Choose Your Tool</a>
                <a href="https://huggingface.co/collections/imageomics/bioclip" target="_blank" class="btn btn-outline">Explore Collection</a>
            </div>
        </div>
    </section>

    <section id="guide" class="section">
        <div class="container">
            <h2 class="section-title">Which BioCLIP component do you need?</h2>
            
            <div class="decision-guide">
                <div class="guide-card">
                    <span class="guide-icon">üöÄ</span>
                    <h3 class="guide-title">State-of-the-Art Accuracy</h3>
                    <p class="guide-desc">I need the latest model with the highest accuracy (ViT-L) and emergent biological capabilities.</p>
                    <a href="#bioclip-2" class="guide-link">Go to BioCLIP 2 &rarr;</a>
                </div>

                <div class="guide-card">
                    <span class="guide-icon">üêç</span>
                    <h3 class="guide-title">Easy Python Integration</h3>
                    <p class="guide-desc">I want to use BioCLIP in my code without dealing with complex ML infrastructure.</p>
                    <a href="#pybioclip" class="guide-link">Go to pybioclip &rarr;</a>
                </div>

                <div class="guide-card">
                    <span class="guide-icon">üìú</span>
                    <h3 class="guide-title">Original & Cited</h3>
                    <p class="guide-desc">I need the original ViT-B model described in the 2023 CVPR/arXiv paper.</p>
                    <a href="#bioclip-1" class="guide-link">Go to BioCLIP 1 &rarr;</a>
                </div>

                <div class="guide-card">
                    <span class="guide-icon">üíæ</span>
                    <h3 class="guide-title">Raw Data & Models</h3>
                    <p class="guide-desc">I want to download weights, datasets (TreeOfLife-10M/200M), or see demos.</p>
                    <a href="#collection" class="guide-link">Go to HF Collection &rarr;</a>
                </div>
            </div>
        </div>
    </section>

    <section id="bioclip-2" class="section">
        <div class="container">
            <div class="component-row">
                <div class="component-text">
                    <span class="tag new">Latest Release</span>
                    <h2>BioCLIP 2</h2>
                    <p>
                        The next generation of the model, scaled up to <strong>TreeOfLife-200M</strong>. BioCLIP 2 (ViT-L/14) improves species classification accuracy by over 18% compared to the original.
                    </p>
                    <p>
                        Beyond simple classification, it exhibits emergent properties, such as distinguishing between life stages, sexes, and aligning embeddings with ecological traits like beak size.
                    </p>
                    <ul class="feature-list">
                        <li><strong>Architecture:</strong> ViT-L/14 (Large)</li>
                        <li><strong>Training Data:</strong> 214 Million images (TreeOfLife-200M)</li>
                        <li><strong>Best for:</strong> High-accuracy tasks, fine-grained trait analysis, zero-shot learning.</li>
                    </ul>
                    <a href="https://imageomics.github.io/bioclip-2/" class="btn btn-primary">Visit BioCLIP 2 Site</a>
                    <a href="https://huggingface.co/imageomics/bioclip-2" class="btn btn-outline ml-2">Model Card</a>
                </div>
                <div class="component-image img-bioclip2">
                    BioCLIP 2 Visualization
                </div>
            </div>
        </div>
    </section>

    <section id="pybioclip" class="section bg-light">
        <div class="container">
            <div class="component-row">
                <div class="component-text">
                    <span class="tag tool">Developer Tool</span>
                    <h2>pybioclip</h2>
                    <p>
                        A user-friendly Python package and command-line tool designed to make BioCLIP models accessible to everyone, regardless of ML expertise.
                    </p>
                    <p>
                        It handles preprocessing, model downloading, and batch optimization automatically.
                    </p>
                    <div class="code-block">
pip install pybioclip
bioclip predict my_image.jpg</div>
                    <ul class="feature-list">
                        <li>Simple command-line interface (CLI).</li>
                        <li>Python API for custom scripts.</li>
                        <li>Optimized for batch processing of large image sets.</li>
                    </ul>
                    <a href="https://imageomics.github.io/pybioclip/" class="btn btn-primary">Read Documentation</a>
                    <a href="https://github.com/Imageomics/pybioclip" class="btn btn-outline ml-2">View on GitHub</a>
                </div>
                <div class="component-image img-pybioclip">
                    pybioclip CLI
                </div>
            </div>
        </div>
    </section>

    <section id="bioclip-1" class="section">
        <div class="container">
            <div class="component-row">
                <div class="component-text">
                    <span class="tag">Original Model</span>
                    <h2>BioCLIP (Original)</h2>
                    <p>
                        The original foundation model presented in "BioCLIP: A Vision Foundation Model for the Tree of Life". It established the standard for using CLIP architectures in organismal biology.
                    </p>
                    <p>
                        Trained on the TreeOfLife-10M dataset, it covers over 450,000 taxa and learns a hierarchical representation that aligns with the biological taxonomy.
                    </p>
                    <ul class="feature-list">
                        <li><strong>Architecture:</strong> ViT-B/16 (Base)</li>
                        <li><strong>Training Data:</strong> 10 Million images</li>
                        <li><strong>Best for:</strong> General purpose baselines, reproducing original paper results.</li>
                    </ul>
                    <a href="https://imageomics.github.io/bioclip/" class="btn btn-primary">Visit BioCLIP 1 Site</a>
                    <a href="https://arxiv.org/abs/2311.18803" class="btn btn-outline ml-2">Read Paper</a>
                </div>
                <div class="component-image img-bioclip1">
                    BioCLIP 1 Structure
                </div>
            </div>
        </div>
    </section>

    <section id="collection" class="section bg-light">
        <div class="container">
            <div class="component-row">
                <div class="component-text">
                    <span class="tag tool">Repository</span>
                    <h2>Hugging Face Collection</h2>
                    <p>
                        The central warehouse for all BioCLIP assets. This collection aggregates all versions of the models, the training datasets, and interactive demos.
                    </p>
                    <p>
                        Use this if you need direct access to raw model weights (SafeTensors/PyTorch) or want to download the massive TreeOfLife datasets.
                    </p>
                    <ul class="feature-list">
                        <li><strong>Models:</strong> BioCLIP 1, BioCLIP 2, BioCLIP-iNat.</li>
                        <li><strong>Datasets:</strong> TreeOfLife-10M, TreeOfLife-200M, Rare Species.</li>
                        <li><strong>Demos:</strong> Interactive Gradio apps for zero-shot classification.</li>
                    </ul>
                    <a href="https://huggingface.co/collections/imageomics/bioclip" class="btn btn-primary">Browse Collection</a>
                </div>
                <div class="component-image img-hf">
                    ü§ó Hugging Face Collection
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container footer-content">
            <div class="footer-col">
                <h4>BioCLIP Project</h4>
                <p class="footer-desc">
                    Developing foundation models to accelerate biological discovery and conservation through computer vision.
                </p>
            </div>
            <div class="footer-col">
                <h4>Resources</h4>
                <ul class="footer-links">
                    <li><a href="https://imageomics.github.io/bioclip-2/">BioCLIP 2</a></li>
                    <li><a href="https://imageomics.github.io/bioclip/">BioCLIP 1</a></li>
                    <li><a href="https://imageomics.github.io/pybioclip/">pybioclip Docs</a></li>
                </ul>
            </div>
            <div class="footer-col">
                <h4>Community</h4>
                <ul class="footer-links">
                    <li><a href="https://github.com/Imageomics">Imageomics GitHub</a></li>
                    <li><a href="https://huggingface.co/imageomics">Hugging Face Profile</a></li>
                </ul>
            </div>
        </div>
        <div class="container footer-bottom">
            &copy; 2025 BioCLIP Project. All rights reserved.
        </div>
    </footer>
</body>
</html>